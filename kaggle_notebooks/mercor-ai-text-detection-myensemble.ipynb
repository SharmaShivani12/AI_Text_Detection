{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":117171,"databundleVersionId":14089262,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üß† Mercor AI Text Detection ‚Äî DeBERTa + RoBERTa Ensemble\n\nThis notebook tackles the **Mercor AI Text Detection** challenge ‚Äî identifying whether a written response is **AI-generated** or **human-written**.\n\nWe fine-tune two transformer models ‚Äî **DeBERTa-v3-small** and **RoBERTa-base** ‚Äî and combine their predictions using an **ensemble** approach to create a more balanced and accurate final model.\n\n---\n\n## ‚öôÔ∏è Environment & Dataset\n\n**Environment**\n- PyTorch `2.6.0+cu124`\n- Transformers `4.53.3`\n- Datasets `4.4.1`\n\n**Dataset path:** `/kaggle/input/mercor-ai-detection`\n\n**Files included**\n- `train.csv` ‚Äî labeled training data  \n- `test.csv` ‚Äî unlabeled test set  \n- `sample_submission.csv` ‚Äî submission format reference  \n\nEach record contains:\n- `id` ‚Äî unique identifier  \n- `topic` ‚Äî the given question or prompt  \n- `answer` ‚Äî the written text  \n- `is_cheating` ‚Äî label (1 = AI-generated, 0 = human-written)\n\n---\n\n## üöÄ Pipeline Overview\n\n### 1Ô∏è‚É£ Data Preparation\n- Combine `topic` and `answer` into a single input string.  \n- Use a stratified 80/20 split for train and validation.  \n- Tokenize using Hugging Face `AutoTokenizer` (`max_length = 384`).\n\n### 2Ô∏è‚É£ Model Training\nTwo strong pretrained models are fine-tuned:\n- üü¶ **microsoft/deberta-v3-small** ‚Äî excels at contextual understanding.  \n- üü™ **roberta-base** ‚Äî robust at text classification and generalization.\n\nTraining setup:\n- Learning rate: `2e-5`  \n- Batch size: `8`  \n- Epochs: `7`  \n- Early stopping: patience = 3  \n- Metric: **ROC-AUC**\n\n---\n\n## üìà Sample Training Progress (DeBERTa)\n\n| Epoch | Train Loss | Val Loss | ROC-AUC |\n|:------|:-----------:|:---------:|:-------:|\n| 1 | 0.614 | 0.484 | 0.925 |\n| 2 | 0.266 | 0.517 | 0.958 |\n| 3 | 0.182 | 0.184 | **0.981** |\n\nDeBERTa rapidly improves over a few epochs, reaching excellent validation AUC.  \nRoBERTa performs similarly, and together they form a reliable, well-generalized solution.\n\n---\n\n## ü§ù Why Use an Ensemble?\n\nAn **ensemble** combines predictions from multiple models to make a single, more stable prediction.  \nInstead of relying on one model‚Äôs biases or weaknesses, the ensemble leverages their strengths ‚Äî like averaging multiple expert opinions.\n\nIn this notebook:\n```python\nfinal_preds = (deberta_preds + roberta_preds) / 2\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output \n# when you create a version using \"Save & Run All\". \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session.\n\n# ====================================================\n# Verify Environment\n# ====================================================\nimport torch, transformers, datasets\n\nprint(\"Torch:\", torch.__version__)\nprint(\"Transformers:\", transformers.__version__)\nprint(\"Datasets:\", datasets.__version__)\n\n# ====================================================\n# Mercor AI Text Detection - DeBERTa + RoBERTa Ensemble\n# ====================================================\nimport gc\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    EarlyStoppingCallback\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nDATA_PATH = \"/kaggle/input/mercor-ai-detection\"\nSEED = 42\nMAX_LEN = 384\nEPOCHS = 7\nLR = 2e-5\nBATCH_SIZE = 8\n\ngc.collect()\ntorch.cuda.empty_cache()\n\n\ndef load_and_prepare():\n    train = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n    test = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n    train[\"text\"] = train[\"topic\"].astype(str) + \" \" + train[\"answer\"].astype(str)\n    test[\"text\"] = test[\"topic\"].astype(str) + \" \" + test[\"answer\"].astype(str)\n    tr, val = train_test_split(train, test_size=0.2, stratify=train[\"is_cheating\"], random_state=SEED)\n    return tr, val, test\n\n\ndef tokenize(tokenizer, ds):\n    def fn(batch):\n        return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n    return ds.map(fn, batched=True)\n\n\ndef train_and_predict(model_name, train_df, val_df, test_df):\n    print(f\"\\nüîπ Training {model_name}\")\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    train_ds = Dataset.from_pandas(train_df)\n    val_ds = Dataset.from_pandas(val_df)\n    test_ds = Dataset.from_pandas(test_df)\n\n    train_ds = tokenize(tokenizer, train_ds)\n    val_ds = tokenize(tokenizer, val_ds)\n    test_ds = tokenize(tokenizer, test_ds)\n\n    train_ds = train_ds.rename_column(\"is_cheating\", \"labels\")\n    val_ds = val_ds.rename_column(\"is_cheating\", \"labels\")\n\n    cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n    train_ds.set_format(\"torch\", columns=cols)\n    val_ds.set_format(\"torch\", columns=cols)\n    test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"id\"])\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n    model.config.use_cache = False  # required when using gradient checkpointing\n# model.gradient_checkpointing_enable()  # Uncomment later if you want to experiment\n\n\n    def compute_metrics(p):\n        logits, labels = p\n        preds = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n        return {\"roc_auc\": roc_auc_score(labels, preds)}\n\n    args = TrainingArguments(\n        output_dir=f\"./results_{model_name.split('/')[-1]}\",\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        learning_rate=LR,\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE,\n        num_train_epochs=EPOCHS,\n        metric_for_best_model=\"roc_auc\",\n        load_best_model_at_end=True,\n        seed=SEED,\n        fp16=torch.cuda.is_available(),\n        logging_strategy=\"epoch\",\n        save_total_limit=1,\n        report_to=\"none\",\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=train_ds,\n        eval_dataset=val_ds,\n        compute_metrics=compute_metrics,\n        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n    )\n\n    trainer.train()\n\n    preds = trainer.predict(val_ds)\n    print(\"Validation ROC-AUC:\", preds.metrics[\"test_roc_auc\"])\n\n    test_logits = trainer.predict(test_ds).predictions\n    test_preds = torch.softmax(torch.tensor(test_logits), dim=1)[:, 1].numpy()\n\n    # Free GPU memory before next model\n    del model, trainer\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return test_preds, preds.metrics[\"test_roc_auc\"]\n\n\ntrain_df, val_df, test_df = load_and_prepare()\n\ndeberta_preds, deb_auc = train_and_predict(\"microsoft/deberta-v3-small\", train_df, val_df, test_df)\nroberta_preds, rob_auc = train_and_predict(\"roberta-base\", train_df, val_df, test_df)\n\nfinal_preds = (deberta_preds + roberta_preds) / 2\n\nsubmission = pd.DataFrame({\"id\": test_df[\"id\"], \"is_cheating\": final_preds})\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"\\n‚úÖ Ensemble complete\")\nprint(f\"DeBERTa ROC-AUC: {deb_auc:.4f} | RoBERTa ROC-AUC: {rob_auc:.4f}\")\nprint(\"Saved submission.csv for upload üöÄ\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-09T15:31:14.949622Z","iopub.execute_input":"2025-11-09T15:31:14.949949Z","iopub.status.idle":"2025-11-09T16:52:32.901023Z","shell.execute_reply.started":"2025-11-09T15:31:14.949916Z","shell.execute_reply":"2025-11-09T16:52:32.899814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\nsub = pd.read_csv(\"submission.csv\")\nsub.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T16:54:30.706652Z","iopub.execute_input":"2025-11-09T16:54:30.707824Z","iopub.status.idle":"2025-11-09T16:54:30.74027Z","shell.execute_reply.started":"2025-11-09T16:54:30.707789Z","shell.execute_reply":"2025-11-09T16:54:30.739469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub.info()\nprint(f\"\\nRows: {len(sub)} | Columns: {list(sub.columns)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T16:55:02.142531Z","iopub.execute_input":"2025-11-09T16:55:02.142868Z","iopub.status.idle":"2025-11-09T16:55:02.170343Z","shell.execute_reply.started":"2025-11-09T16:55:02.14284Z","shell.execute_reply":"2025-11-09T16:55:02.169436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = pd.read_csv(\"/kaggle/input/mercor-ai-detection/sample_submission.csv\")\nprint(\"Sample shape:\", sample.shape)\nprint(\"Submission shape:\", sub.shape)\n\nassert list(sub.columns) == list(sample.columns), \"‚ö†Ô∏è Column names don't match sample_submission.csv!\"\nprint(\"‚úÖ Column names verified\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T16:55:15.790376Z","iopub.execute_input":"2025-11-09T16:55:15.790716Z","iopub.status.idle":"2025-11-09T16:55:15.803285Z","shell.execute_reply.started":"2025-11-09T16:55:15.790686Z","shell.execute_reply":"2025-11-09T16:55:15.801963Z"}},"outputs":[],"execution_count":null}]}